# There are two ways that you can see a more human-readable form of this
# documentation. Either using the swagger editor or swagger-ui.
# To view using the swagger editor:
#   1. Go to http://editor.swagger.io
#   2. Copy and paste the contents of this file into the editor
#
# OR to view using swagger-ui:
#   1. Go to http://petstore.swagger.io
#   2. Put https://raw.githubusercontent.com/openaustralia/morph/morph-server-docs/docs/morph-server/swagger.yaml
#      in the textbox at the top
#   3. Hit the "Explore" button

# TODO: Add an api endpoint to get the overall status of the current run. e.g. how
# long has it been running. What stage is it in? Would this endpoint also be the
# appropriate way to get access to the metrics instead?

# TODO: Add an /runs index endpoint to list all the current runs

swagger: '2.0'

# This is your document metadata
info:
  version: "0.0.1"
  title: A straw-man for the morph server API
  description: |
    Some initial straw-man documentation for the morph server,
    a low level scraper api, suggested in
    https://github.com/openaustralia/morph/issues/647

securityDefinitions:
  api_key:
    type: apiKey
    name: api_key
    in: header

# Describe your paths here
paths:
  # This is a path endpoint. Change it.
  /runs:
    # This is a HTTP operation
    post:
      summary: Start a scraper run
      # Describe this verb here. Note: you can use markdown
      description: |
        Actually start a scraper. Give it the scraper code (in any language supported
        by buildstep) and any associated data it needs locally. This will return as
        soon as the scraper is compiling and/or running with the "run ID" which
        uniquelly identifies this scraper run. You will need this run ID to
        subsequently track and access this scraper.
      # This is array of GET operation parameters:
      consumes:
        - multipart/form-data
      parameters:
        -
          name: code
          in: formData
          description: |
            Directory with code, configuration and data to run. Everything needs
            to be tarred up.
          required: true
          type: file
        -
          name: environment
          in: formData
          description: |
            Environment variables to set for the scraper run. Each environment
            should be passed in the form `VARIABLE=VALUE`.
          type: array
          items:
            type: string
      schemes:
        - https
      security:
        -
          api_key: []
      # Expected responses for this operation:
      responses:
        # Response code
        200:
          description: Started successfully
          # A schema describing your response object.
          # Use JSON Schema format
          schema:
            title: run_id
            type: integer
            description: |
              Uniquelly identifies this scraper run. Needed for any subsequent API calls
              for this run.

  /runs/{id}/events:
    get:
      summary: Attach to scraper event stream
      description: |
        Watch what is happening to a scraper in real-time as it gets compiled and runs.
        By default this will stream all events that have occurred from the scraper
        getting started until now and then as new events occur stream those in real-time.
        If for any reason this connection dies (or you stop it), you can reconnect with
        the last successfully received event ID and the stream will start from the next
        event.

        Note that even if a scraper has completed or failed calling this should succeed.
        As in it should be possible to get the whole event log of everything that happened
        even if nothing is currently running.

        **TODO**: Figure out how to represent JSON streams in swagger in response below
      parameters:
        -
          name: id
          in: path
          description: The event ID (as returned by starting a scraper run)
          type: integer
          required: true
      responses:
        200:
          description: Attached
          schema:
            type: array
            items:
              $ref: '#/definitions/Event'

  /runs/{id}/stop:
    post:
      summary: Stop scraper run
      description: Use this when you want to stop a running scraper cleanly
      parameters:
        -
          name: id
          in: path
          description: The event ID (as returned by starting a scraper run)
          type: integer
          required: true
      responses:
        200:
          description: Successfully stopped
        # TODO: Response for not stopping succesfully

  /runs/{id}/metrics:
    get:
      summary: Get metrics for completed stages of the scraper run
      description: |
        Usually at the end of a scraper run you want to know stuff about how
        much resources it took.
      parameters:
        -
          name: id
          in: path
          description: The event ID (as returned by starting a scraper run)
          type: integer
          required: true
      # TODO: What to do if the scraper run hasn't actually finished?
      responses:
        200:
          description: Success
          schema:
            # TODO: Probably want to turn this into a hash with stage as the key
            type: array
            items:
              type: object
              properties:
                stage:
                  $ref: '#/definitions/Stage'
                resource_usage:
                  $ref: '#/definitions/ResourceUsage'

  /runs/{id}/file:
    get:
      summary: Get file
      description: |
        Usually at the end of the scraper run you want to grab the contents
        of a file which is probably the result of scraping. This allows you
        to do that.
      # TODO: What to do if the scraper run hasn't actually finished?
      parameters:
        -
          name: id
          in: path
          description: The event ID (as returned by starting a scraper run)
          type: integer
          required: true
        -
          name: path
          in: query
          description: The path to the file to grab
          type: string
          required: true
      responses:
        200:
          description: Success
          schema:
            type: file

  /runs/{id}:
    delete:
      summary: Finalise scraper run
      description: |
        This does final clean up of everything associated with a scraper run.
        After doing this it's not possible to get any information about the run.
        So, make sure you have everything you need before you call this.

        If a scraper isn't stopped or finished after a certain amount of
        time it should be automatically cleaned up. This is to ensure that
        the morph server is only stateful over the short term.

      parameters:
        -
          name: id
          in: path
          description: The event ID (as returned by starting a scraper run)
          type: integer
          required: true
      # TODO: What to do if the scraper run hasn't actually finished?
      # TODO: Add failure response
      responses:
        200:
          description: Success

definitions:
  Stage:
    type: string
    description: The stage of the life-cycle of the run
    enum:
      - queued
      - compiling
      - running
      - stopped

  ResourceUsage:
    type: object
    description: |
      Resources used by a process. This information is recorded as part of
      the metrics for a scraper run.

      The names of metrics are all copied from the structure
      returned by `getrusage(2)` (with the exception of `wall_time`)
    properties:
      wall_time:
        description: Wall clock
        type: number
      utime:
        description: |
          This is the total amount of time spent executing in user
          mode, expressed in a timeval structure (seconds plus
          microseconds).
        type: number
      stime:
        description: |
          This is the total amount of time spent executing in
          kernel mode, expressed in a timeval structure (seconds
          plus microseconds).
        type: number
      maxrss:
        description: |
          This is the maximum resident set size used (in kilobytes).
          For RUSAGE_CHILDREN, this is the resident set size of the
          largest child, not the maximum resident set size of the
          process tree.
        type: integer
      minflt:
        description: |
          The number of page faults serviced without any I/O
          activity; here I/O activity is avoided by "reclaiming" a
          page frame from the list of pages awaiting reallocation.
        type: integer
      majflt:
        description: |
          The number of page faults serviced that required I/O
          activity.
        type: integer
      inblock:
        description: |
          The number of times the file system had to perform input.
        type: integer
      oublock:
        description: |
          The number of times the file system had to perform output.
        type: integer
      nvcsw:
        description: |
          The number of times a context switch resulted due to a
          process voluntarily giving up the processor before its
          time slice was completed (usually to await availability
          of a resource).
        type: integer
      nivcsw:
        description: |
          The number of times a context switch resulted due to a
          higher priority process becoming runnable or because
          the current process exceeded its time slice.
        type: integer

  Event:
    type: object
    discriminator: type
    properties:
      id:
        type: integer
      type:
        type: string
      time:
        type: string
        format: date-time
        description: Date and time of event
      stage:
        $ref: '#/definitions/Stage'
    required:
      - id
      - type
      - time
      - stage

  LogEvent:
    type: object
    description: Console output event (from scraper run)
    allOf:
    - $ref: '#/definitions/Event'
    - type: object
      properties:
        source:
          type: string
          enum: ["stdout", "stderr"]
          description: |
            Source of the message. e.g. `stdout`, `stderr`
        text:
          type: string
          description: Console message
      required:
        - source
        - text

  ConnectionEvent:
    type: object
    description: http/https connection made to the outside world
    allOf:
    - $ref: '#/definitions/Event'
    - type: object
      properties:
        method:
          type: string
          description: REST method used (e.g. GET, PUT..)
        scheme:
          type: string
          description: Whether http or https
        domain:
          type: string
          description: Name of server being connected to
        path:
          type: string
          description: Path bit of url from domain being connected to
        request_size:
          type: integer
        response_size:
          type: integer
        response_code:
          type: integer
      required:
        - method
        - scheme
        - domain
        - path
        - request_size
        - response_size
        - response_code
  StageChangeEvent:
    type: object
    description: |
      Event for moving from one stage to another. e.g. queued, compiling,
      running, exited with particular exit code. The stage is the stage that
      we're moving into.
    properties:
      exitCode:
        type: integer
        description: |
          On stage "stopped", includes the exitCode of the
          running process.
