:markdown
  The `scraperwiki` Python library makes it easy to store data in an SQLite database.
  When you create a new scraper via morph.io we include a version of the library that writes data to the correct database name in the default `requirements.txt` file.

  To save data all you need to do is call the [`scraperwiki.sql.save` method](https://github.com/openaustralia/scraperwiki-python/tree/morph_defaults#saving-data).
  Creating the database and setting up tables is done automagically by the library:

:coderay
  #!python
  scraperwiki.sqlite.save(unique_keys=['name'], data={"name": "susan", "occupation": "software developer"})
